{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5f58b8",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c0d00887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy, seaborn, pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8718c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split, RepeatedStratifiedKFold, cross_val_score, LogisticRegression, roc_curve, roc_auc_score,\n",
    "# confusion_matrix, precision_recall_curve, auc, f_classif, Pipeline, BaseEstimator, TransformerMixin, chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import datasets, linear_model \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.feature_selection import SelectFpr , f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n",
    "from datetime import date\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452fe749",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8dfd3c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\anshu\\Downloads\\credit_risk_dataset.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5db1ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000           4975.0   36 months   \n",
       "1  1077430    1314167       2500         2500           2500.0   60 months   \n",
       "2  1077175    1313524       2400         2400           2400.0   36 months   \n",
       "3  1076863    1277178      10000        10000          10000.0   36 months   \n",
       "4  1075358    1311748       3000         3000           3000.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... total_bal_il il_util  \\\n",
       "0     10.65       162.87     B        B2  ...          NaN     NaN   \n",
       "1     15.27        59.83     C        C4  ...          NaN     NaN   \n",
       "2     15.96        84.33     C        C5  ...          NaN     NaN   \n",
       "3     13.49       339.31     C        C1  ...          NaN     NaN   \n",
       "4     12.69        67.79     B        B5  ...          NaN     NaN   \n",
       "\n",
       "  open_rv_12m  open_rv_24m max_bal_bc all_util total_rev_hi_lim inq_fi  \\\n",
       "0         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "1         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "2         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "3         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "4         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "\n",
       "  total_cu_tl inq_last_12m  \n",
       "0         NaN          NaN  \n",
       "1         NaN          NaN  \n",
       "2         NaN          NaN  \n",
       "3         NaN          NaN  \n",
       "4         NaN          NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db398b",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0a185963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
       "       'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
       "       'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose',\n",
       "       'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq',\n",
       "       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'initial_list_status', 'out_prncp',\n",
       "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
       "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
       "       'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt',\n",
       "       'next_pymnt_d', 'last_credit_pull_d', 'collections_12_mths_ex_med',\n",
       "       'mths_since_last_major_derog', 'policy_code', 'application_type',\n",
       "       'annual_inc_joint', 'dti_joint', 'verification_status_joint',\n",
       "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
       "       'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
       "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
       "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl',\n",
       "       'inq_last_12m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the dataset(use the data dictionary)\n",
    "# look at the columns, which data type is present in a column, range of values in each column, their mean, etc.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "336cf009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 466285 entries, 0 to 466284\n",
      "Data columns (total 74 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           466285 non-null  int64  \n",
      " 1   member_id                    466285 non-null  int64  \n",
      " 2   loan_amnt                    466285 non-null  int64  \n",
      " 3   funded_amnt                  466285 non-null  int64  \n",
      " 4   funded_amnt_inv              466285 non-null  float64\n",
      " 5   term                         466285 non-null  object \n",
      " 6   int_rate                     466285 non-null  float64\n",
      " 7   installment                  466285 non-null  float64\n",
      " 8   grade                        466285 non-null  object \n",
      " 9   sub_grade                    466285 non-null  object \n",
      " 10  emp_title                    438697 non-null  object \n",
      " 11  emp_length                   445277 non-null  object \n",
      " 12  home_ownership               466285 non-null  object \n",
      " 13  annual_inc                   466281 non-null  float64\n",
      " 14  verification_status          466285 non-null  object \n",
      " 15  issue_d                      466285 non-null  object \n",
      " 16  loan_status                  466285 non-null  object \n",
      " 17  pymnt_plan                   466285 non-null  object \n",
      " 18  url                          466285 non-null  object \n",
      " 19  desc                         125983 non-null  object \n",
      " 20  purpose                      466285 non-null  object \n",
      " 21  title                        466265 non-null  object \n",
      " 22  zip_code                     466285 non-null  object \n",
      " 23  addr_state                   466285 non-null  object \n",
      " 24  dti                          466285 non-null  float64\n",
      " 25  delinq_2yrs                  466256 non-null  float64\n",
      " 26  earliest_cr_line             466256 non-null  object \n",
      " 27  inq_last_6mths               466256 non-null  float64\n",
      " 28  mths_since_last_delinq       215934 non-null  float64\n",
      " 29  mths_since_last_record       62638 non-null   float64\n",
      " 30  open_acc                     466256 non-null  float64\n",
      " 31  pub_rec                      466256 non-null  float64\n",
      " 32  revol_bal                    466285 non-null  int64  \n",
      " 33  revol_util                   465945 non-null  float64\n",
      " 34  total_acc                    466256 non-null  float64\n",
      " 35  initial_list_status          466285 non-null  object \n",
      " 36  out_prncp                    466285 non-null  float64\n",
      " 37  out_prncp_inv                466285 non-null  float64\n",
      " 38  total_pymnt                  466285 non-null  float64\n",
      " 39  total_pymnt_inv              466285 non-null  float64\n",
      " 40  total_rec_prncp              466285 non-null  float64\n",
      " 41  total_rec_int                466285 non-null  float64\n",
      " 42  total_rec_late_fee           466285 non-null  float64\n",
      " 43  recoveries                   466285 non-null  float64\n",
      " 44  collection_recovery_fee      466285 non-null  float64\n",
      " 45  last_pymnt_d                 465909 non-null  object \n",
      " 46  last_pymnt_amnt              466285 non-null  float64\n",
      " 47  next_pymnt_d                 239071 non-null  object \n",
      " 48  last_credit_pull_d           466243 non-null  object \n",
      " 49  collections_12_mths_ex_med   466140 non-null  float64\n",
      " 50  mths_since_last_major_derog  98974 non-null   float64\n",
      " 51  policy_code                  466285 non-null  int64  \n",
      " 52  application_type             466285 non-null  object \n",
      " 53  annual_inc_joint             0 non-null       float64\n",
      " 54  dti_joint                    0 non-null       float64\n",
      " 55  verification_status_joint    0 non-null       float64\n",
      " 56  acc_now_delinq               466256 non-null  float64\n",
      " 57  tot_coll_amt                 396009 non-null  float64\n",
      " 58  tot_cur_bal                  396009 non-null  float64\n",
      " 59  open_acc_6m                  0 non-null       float64\n",
      " 60  open_il_6m                   0 non-null       float64\n",
      " 61  open_il_12m                  0 non-null       float64\n",
      " 62  open_il_24m                  0 non-null       float64\n",
      " 63  mths_since_rcnt_il           0 non-null       float64\n",
      " 64  total_bal_il                 0 non-null       float64\n",
      " 65  il_util                      0 non-null       float64\n",
      " 66  open_rv_12m                  0 non-null       float64\n",
      " 67  open_rv_24m                  0 non-null       float64\n",
      " 68  max_bal_bc                   0 non-null       float64\n",
      " 69  all_util                     0 non-null       float64\n",
      " 70  total_rev_hi_lim             396009 non-null  float64\n",
      " 71  inq_fi                       0 non-null       float64\n",
      " 72  total_cu_tl                  0 non-null       float64\n",
      " 73  inq_last_12m                 0 non-null       float64\n",
      "dtypes: float64(46), int64(6), object(22)\n",
      "memory usage: 263.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cc753927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "member_id                0\n",
       "loan_amnt                0\n",
       "funded_amnt              0\n",
       "funded_amnt_inv          0\n",
       "                     ...  \n",
       "all_util            466285\n",
       "total_rev_hi_lim     70276\n",
       "inq_fi              466285\n",
       "total_cu_tl         466285\n",
       "inq_last_12m        466285\n",
       "Length: 74, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of columns that have more than 80% null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e8794aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emp_title', 'emp_length', 'annual_inc', 'desc', 'title', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq',\n",
       "       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_util',\n",
       "       'total_acc', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d',\n",
       "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
       "       'annual_inc_joint', 'dti_joint', 'verification_status_joint',\n",
       "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
       "       'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
       "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
       "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl',\n",
       "       'inq_last_12m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().sum() > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "987bca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete columns containing 80% or more than 80% NAN values\n",
    "perc = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "161a7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count =  int(((100 - perc)/100)*df.shape[0] + 1)\n",
    "df = df.dropna( axis=1, thresh=min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2ff9f66a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 466285 entries, 0 to 466284\n",
      "Data columns (total 56 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           466285 non-null  int64  \n",
      " 1   member_id                    466285 non-null  int64  \n",
      " 2   loan_amnt                    466285 non-null  int64  \n",
      " 3   funded_amnt                  466285 non-null  int64  \n",
      " 4   funded_amnt_inv              466285 non-null  float64\n",
      " 5   term                         466285 non-null  object \n",
      " 6   int_rate                     466285 non-null  float64\n",
      " 7   installment                  466285 non-null  float64\n",
      " 8   grade                        466285 non-null  object \n",
      " 9   sub_grade                    466285 non-null  object \n",
      " 10  emp_title                    438697 non-null  object \n",
      " 11  emp_length                   445277 non-null  object \n",
      " 12  home_ownership               466285 non-null  object \n",
      " 13  annual_inc                   466281 non-null  float64\n",
      " 14  verification_status          466285 non-null  object \n",
      " 15  issue_d                      466285 non-null  object \n",
      " 16  loan_status                  466285 non-null  object \n",
      " 17  pymnt_plan                   466285 non-null  object \n",
      " 18  url                          466285 non-null  object \n",
      " 19  desc                         125983 non-null  object \n",
      " 20  purpose                      466285 non-null  object \n",
      " 21  title                        466265 non-null  object \n",
      " 22  zip_code                     466285 non-null  object \n",
      " 23  addr_state                   466285 non-null  object \n",
      " 24  dti                          466285 non-null  float64\n",
      " 25  delinq_2yrs                  466256 non-null  float64\n",
      " 26  earliest_cr_line             466256 non-null  object \n",
      " 27  inq_last_6mths               466256 non-null  float64\n",
      " 28  mths_since_last_delinq       215934 non-null  float64\n",
      " 29  open_acc                     466256 non-null  float64\n",
      " 30  pub_rec                      466256 non-null  float64\n",
      " 31  revol_bal                    466285 non-null  int64  \n",
      " 32  revol_util                   465945 non-null  float64\n",
      " 33  total_acc                    466256 non-null  float64\n",
      " 34  initial_list_status          466285 non-null  object \n",
      " 35  out_prncp                    466285 non-null  float64\n",
      " 36  out_prncp_inv                466285 non-null  float64\n",
      " 37  total_pymnt                  466285 non-null  float64\n",
      " 38  total_pymnt_inv              466285 non-null  float64\n",
      " 39  total_rec_prncp              466285 non-null  float64\n",
      " 40  total_rec_int                466285 non-null  float64\n",
      " 41  total_rec_late_fee           466285 non-null  float64\n",
      " 42  recoveries                   466285 non-null  float64\n",
      " 43  collection_recovery_fee      466285 non-null  float64\n",
      " 44  last_pymnt_d                 465909 non-null  object \n",
      " 45  last_pymnt_amnt              466285 non-null  float64\n",
      " 46  next_pymnt_d                 239071 non-null  object \n",
      " 47  last_credit_pull_d           466243 non-null  object \n",
      " 48  collections_12_mths_ex_med   466140 non-null  float64\n",
      " 49  mths_since_last_major_derog  98974 non-null   float64\n",
      " 50  policy_code                  466285 non-null  int64  \n",
      " 51  application_type             466285 non-null  object \n",
      " 52  acc_now_delinq               466256 non-null  float64\n",
      " 53  tot_coll_amt                 396009 non-null  float64\n",
      " 54  tot_cur_bal                  396009 non-null  float64\n",
      " 55  total_rev_hi_lim             396009 non-null  float64\n",
      "dtypes: float64(28), int64(6), object(22)\n",
      "memory usage: 199.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "21713972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns\n",
    "def DuplicateColumns(df):\n",
    "    duplicatenames = set()\n",
    "    for x in range(df.shape[1]):\n",
    "        col = df.iloc[:, x]\n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "            othercol = df.iloc[:, y]\n",
    "            if col.equals(othercol):\n",
    "                duplicatenames.add(df.colums.values[y])\n",
    "    return list(duplicatenames)\n",
    "df = df.drop(columns = DuplicateColumns(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a3bbe42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'member_id',\n",
       " 'loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_title',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'verification_status',\n",
       " 'issue_d',\n",
       " 'loan_status',\n",
       " 'pymnt_plan',\n",
       " 'url',\n",
       " 'desc',\n",
       " 'purpose',\n",
       " 'title',\n",
       " 'zip_code',\n",
       " 'addr_state',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'earliest_cr_line',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'recoveries',\n",
       " 'collection_recovery_fee',\n",
       " 'last_pymnt_d',\n",
       " 'last_pymnt_amnt',\n",
       " 'next_pymnt_d',\n",
       " 'last_credit_pull_d',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'policy_code',\n",
       " 'application_type',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'total_rev_hi_lim']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a1534071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant(no longer useful) and forward-looking columns\n",
    "df_drop = df.drop(labels = ['id','member_id','sub_grade','emp_title','url','desc','title','zip_code','total_rec_prncp','total_rec_late_fee','recoveries','collection_recovery_fee','next_pymnt_d'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f3a847b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jan-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jan-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Jan-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jan-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  funded_amnt_inv        term  int_rate  installment  \\\n",
       "0       5000         5000           4975.0   36 months     10.65       162.87   \n",
       "1       2500         2500           2500.0   60 months     15.27        59.83   \n",
       "2       2400         2400           2400.0   36 months     15.96        84.33   \n",
       "3      10000        10000          10000.0   36 months     13.49       339.31   \n",
       "4       3000         3000           3000.0   60 months     12.69        67.79   \n",
       "\n",
       "  grade emp_length home_ownership  annual_inc  ... last_pymnt_amnt  \\\n",
       "0     B  10+ years           RENT     24000.0  ...          171.62   \n",
       "1     C   < 1 year           RENT     30000.0  ...          119.66   \n",
       "2     C  10+ years           RENT     12252.0  ...          649.91   \n",
       "3     C  10+ years           RENT     49200.0  ...          357.48   \n",
       "4     B     1 year           RENT     80000.0  ...           67.79   \n",
       "\n",
       "  last_credit_pull_d collections_12_mths_ex_med mths_since_last_major_derog  \\\n",
       "0             Jan-16                        0.0                         NaN   \n",
       "1             Sep-13                        0.0                         NaN   \n",
       "2             Jan-16                        0.0                         NaN   \n",
       "3             Jan-15                        0.0                         NaN   \n",
       "4             Jan-16                        0.0                         NaN   \n",
       "\n",
       "  policy_code application_type  acc_now_delinq  tot_coll_amt tot_cur_bal  \\\n",
       "0           1       INDIVIDUAL             0.0           NaN         NaN   \n",
       "1           1       INDIVIDUAL             0.0           NaN         NaN   \n",
       "2           1       INDIVIDUAL             0.0           NaN         NaN   \n",
       "3           1       INDIVIDUAL             0.0           NaN         NaN   \n",
       "4           1       INDIVIDUAL             0.0           NaN         NaN   \n",
       "\n",
       "   total_rev_hi_lim  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-explore the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "78116f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 466285 entries, 0 to 466284\n",
      "Data columns (total 43 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   loan_amnt                    466285 non-null  int64  \n",
      " 1   funded_amnt                  466285 non-null  int64  \n",
      " 2   funded_amnt_inv              466285 non-null  float64\n",
      " 3   term                         466285 non-null  object \n",
      " 4   int_rate                     466285 non-null  float64\n",
      " 5   installment                  466285 non-null  float64\n",
      " 6   grade                        466285 non-null  object \n",
      " 7   emp_length                   445277 non-null  object \n",
      " 8   home_ownership               466285 non-null  object \n",
      " 9   annual_inc                   466281 non-null  float64\n",
      " 10  verification_status          466285 non-null  object \n",
      " 11  issue_d                      466285 non-null  object \n",
      " 12  loan_status                  466285 non-null  object \n",
      " 13  pymnt_plan                   466285 non-null  object \n",
      " 14  purpose                      466285 non-null  object \n",
      " 15  addr_state                   466285 non-null  object \n",
      " 16  dti                          466285 non-null  float64\n",
      " 17  delinq_2yrs                  466256 non-null  float64\n",
      " 18  earliest_cr_line             466256 non-null  object \n",
      " 19  inq_last_6mths               466256 non-null  float64\n",
      " 20  mths_since_last_delinq       215934 non-null  float64\n",
      " 21  open_acc                     466256 non-null  float64\n",
      " 22  pub_rec                      466256 non-null  float64\n",
      " 23  revol_bal                    466285 non-null  int64  \n",
      " 24  revol_util                   465945 non-null  float64\n",
      " 25  total_acc                    466256 non-null  float64\n",
      " 26  initial_list_status          466285 non-null  object \n",
      " 27  out_prncp                    466285 non-null  float64\n",
      " 28  out_prncp_inv                466285 non-null  float64\n",
      " 29  total_pymnt                  466285 non-null  float64\n",
      " 30  total_pymnt_inv              466285 non-null  float64\n",
      " 31  total_rec_int                466285 non-null  float64\n",
      " 32  last_pymnt_d                 465909 non-null  object \n",
      " 33  last_pymnt_amnt              466285 non-null  float64\n",
      " 34  last_credit_pull_d           466243 non-null  object \n",
      " 35  collections_12_mths_ex_med   466140 non-null  float64\n",
      " 36  mths_since_last_major_derog  98974 non-null   float64\n",
      " 37  policy_code                  466285 non-null  int64  \n",
      " 38  application_type             466285 non-null  object \n",
      " 39  acc_now_delinq               466256 non-null  float64\n",
      " 40  tot_coll_amt                 396009 non-null  float64\n",
      " 41  tot_cur_bal                  396009 non-null  float64\n",
      " 42  total_rev_hi_lim             396009 non-null  float64\n",
      "dtypes: float64(24), int64(4), object(15)\n",
      "memory usage: 153.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7300df0",
   "metadata": {},
   "source": [
    "## Identify the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6ac92171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the target variable(target column) no need to code this just identify\n",
    "#loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5f0d11eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fully Paid', 'Charged Off', 'Current', 'Default',\n",
       "       'Late (31-120 days)', 'In Grace Period', 'Late (16-30 days)',\n",
       "       'Does not meet the credit policy. Status:Fully Paid',\n",
       "       'Does not meet the credit policy. Status:Charged Off'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the unique values in the target column\n",
    "df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "37f20874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column based on the target column that will be our target variable\n",
    "df['good_bad'] = np.where(df.loc[:, 'loan_status'].isin(['Charged Off', 'Default', 'Late (31-120 days)','Does not meet the credit policy. Status:Charged Off']), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d7a50128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original target column\n",
    "df.drop(columns = ['loan_status'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62da664",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0af569dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 80/20 while keeping the distribution of bad loans in test set same as that in the pre-split dataset(X_train, y_train, etc)\n",
    "X = df.drop('good_bad', axis = 1)\n",
    "y = df['good_bad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a6a0e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "466280    1\n",
       "466281    0\n",
       "466282    1\n",
       "466283    1\n",
       "466284    1\n",
       "Name: good_bad, Length: 466285, dtype: int32"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7dc94e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(X,y,test_size = 0.2,random_state = 42,stratify = y)\n",
    "X_train, X_test = X_train.copy(), X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d4ba9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifically hard copying the training sets to avoid Pandas' SetttingWithCopyWarning when we play around with this data later on\n",
    "# you can refer to this link https://github.com/scikit-learn/scikit-learn/issues/8723\n",
    "# this is currently an open issue between Pandas and Scikit-Learn teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "45df823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function clean up a column which has values given along with years, assign 0 to NANs and convert to numeric\n",
    "def emp_length_converter(df, column):\n",
    "    df[column] = df[column].str.replace('\\+ years', '')\n",
    "    df[column] = df[column].str.replace('< 1 year', str(0))\n",
    "    df[column] = df[column].str.replace(' years', '')\n",
    "    df[column] = df[column].str.replace(' year', '')\n",
    "    df[column] = pd.to_numeric(df[column])\n",
    "    df[column].fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4cf50e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshu\\AppData\\Local\\Temp\\ipykernel_2160\\2621041749.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[column] = df[column].str.replace('\\+ years', '')\n"
     ]
    }
   ],
   "source": [
    "# apply to X_train\n",
    "emp_length_converter(X_train, 'emp_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6f21a969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., 10.,  3.,  4.,  2.,  0.,  1.,  6.,  5.,  8.,  9.])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm our transformation by looking at unique values of this column\n",
    "X_train['emp_length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9818c5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jan-15', 'Apr-13', 'Jun-14', 'Jan-16', 'Apr-12', 'Nov-12',\n",
       "       'Jun-13', 'Sep-13', 'Jul-12', 'Oct-13', 'May-13', 'Feb-15',\n",
       "       'Aug-15', 'Oct-12', 'Sep-12', nan, 'Dec-12', 'Dec-14', 'Aug-13',\n",
       "       'Nov-13', 'Jan-14', 'Apr-14', 'Aug-14', 'Oct-14', 'Aug-12',\n",
       "       'Jul-14', 'Jul-13', 'Apr-15', 'Feb-14', 'Sep-14', 'Jun-12',\n",
       "       'Feb-13', 'Mar-13', 'May-14', 'Mar-15', 'Jan-13', 'Dec-13',\n",
       "       'Feb-12', 'Mar-14', 'Sep-15', 'Nov-15', 'Dec-15', 'Jan-12',\n",
       "       'Oct-15', 'Nov-14', 'Mar-12', 'May-12', 'Jun-15', 'May-15',\n",
       "       'Jul-15', 'Dec-11', 'Nov-11', 'Oct-11', 'Sep-11', 'Aug-11',\n",
       "       'Jul-11', 'Jun-11', 'May-11', 'Apr-11', 'Mar-11', 'Feb-11',\n",
       "       'Jan-11', 'Dec-10', 'Nov-10', 'Oct-10', 'Sep-10', 'Aug-10',\n",
       "       'Jul-10', 'Jun-10', 'May-10', 'Apr-10', 'Mar-10', 'Feb-10',\n",
       "       'Jan-10', 'Dec-09', 'Nov-09', 'Oct-09', 'Sep-09', 'Aug-09',\n",
       "       'Jul-09', 'Jun-09', 'May-09', 'Apr-09', 'Mar-09', 'Feb-09',\n",
       "       'Jan-09', 'Dec-08', 'Oct-08', 'Aug-08', 'Jul-08', 'Sep-08',\n",
       "       'Jun-08', 'May-08', 'Nov-08', 'Apr-08', 'Mar-08', 'Feb-08',\n",
       "       'Jan-08', 'Dec-07'], dtype=object)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.last_pymnt_d.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f2544",
   "metadata": {},
   "source": [
    "### Date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ba10320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to convert date columns to datetime format and create a new column as a difference between today and the respective date\n",
    "# details of the function\n",
    "    # store current month\n",
    "    # convert to datetime format\n",
    "    # calculate the difference in months and add to a new column\n",
    "    # make any resulting -ve values to be equal to the max date\n",
    "    # drop the original date column\n",
    "# Note : In current date use the same data to maintain uniformilty across everyone's code. Use : 2020-08-01\n",
    "\n",
    "def convert_date_columns(df,column):\n",
    "    month=df[column].str.split(pat='-',expand = True)[0]\n",
    "    year='20'+df[column].str.split(pat='-',expand = True)[1]\n",
    "    date=year+'-'+month+'-'+'01'\n",
    "    current_date = pd.to_datetime('2020-08-01')\n",
    "    df['mths_since_'+column]=round((current_date-pd.to_datetime(date))/np.timedelta64(1,'M'))\n",
    "    df.drop(columns=[column],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "99a24bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to X_train\n",
    "convert_date_columns(X_train,'last_pymnt_d')\n",
    "convert_date_columns(X_train,'last_credit_pull_d')\n",
    "convert_date_columns(X_train,'issue_d')\n",
    "convert_date_columns(X_train,'earliest_cr_line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4acfad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    373003.000000\n",
      "mean       -398.087517\n",
      "std         536.013355\n",
      "min        -952.000000\n",
      "25%        -900.000000\n",
      "50%        -771.000000\n",
      "75%         203.000000\n",
      "max         247.000000\n",
      "Name: mths_since_earliest_cr_line, dtype: float64\n",
      "count    373028.000000\n",
      "mean         83.252485\n",
      "std          14.339074\n",
      "min          68.000000\n",
      "25%          73.000000\n",
      "50%          79.000000\n",
      "75%          89.000000\n",
      "max         158.000000\n",
      "Name: mths_since_issue_d, dtype: float64\n",
      "count    372717.000000\n",
      "mean         63.289989\n",
      "std          12.803859\n",
      "min          55.000000\n",
      "25%          55.000000\n",
      "50%          56.000000\n",
      "75%          67.000000\n",
      "max         152.000000\n",
      "Name: mths_since_last_pymnt_d, dtype: float64\n",
      "count    372998.000000\n",
      "mean         59.041810\n",
      "std           9.630887\n",
      "min          55.000000\n",
      "25%          55.000000\n",
      "50%          55.000000\n",
      "75%          57.000000\n",
      "max         159.000000\n",
      "Name: mths_since_last_credit_pull_d, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check these new columns\n",
    "print(X_train['mths_since_earliest_cr_line'].describe())\n",
    "print(X_train['mths_since_issue_d'].describe())\n",
    "print(X_train['mths_since_last_pymnt_d'].describe())\n",
    "print(X_train['mths_since_last_credit_pull_d'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf48e3e",
   "metadata": {},
   "source": [
    "### Term column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7832bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to remove 'months' string from the 'term' column and convert it to numeric \n",
    "# use the function on 'term' column of X_Train\n",
    "def loan_term_converter(df, column):\n",
    "    df[column] = pd.to_numeric(df[column].str.replace(' months', ''))\n",
    "\n",
    "loan_term_converter(X_train, 'term')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c666d",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "726b6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first divide training data into categorical and numerical subsets\n",
    "X_train_cat = X_train.select_dtypes(include = 'object').copy()\n",
    "X_train_num = X_train.select_dtypes(include = 'number').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08784212",
   "metadata": {},
   "source": [
    "## Chi-squared statistic for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1224a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty dictionary to store chi-squared test results\n",
    "chi_sq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "12f30784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grade', 'home_ownership', 'verification_status', 'pymnt_plan', 'purpose', 'addr_state', 'initial_list_status', 'application_type']\n"
     ]
    }
   ],
   "source": [
    "Xt = X_train_cat.columns.tolist()\n",
    "print(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f029372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each column in the training set to calculate chi-statistic with the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "79a44211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dictionary to a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the top four categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949f3fa",
   "metadata": {},
   "source": [
    "## ANOVA F-Statistic for numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since f_class_if does not accept missing values, we will do a very crude imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815594f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F Statistic and corresponding p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d26e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e14369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the top 20 features and calculate pair-wise correlations between them\n",
    "# save the top 20 numerical features in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a831c81",
   "metadata": {},
   "source": [
    "## Pair wise correlations to detect multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb639daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pair-wise correlations between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b405e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 2 features based on their multicollinearity with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to drop the 4 categorical features with least p-values for chi squared test, 14 numerical features with least F-Statistic\n",
    "# and 2 numerical features with high multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a483be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40d71b",
   "metadata": {},
   "source": [
    "## creating dummy variables\n",
    "### convert discrete variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbb5d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65ad5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to our final four categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2556e",
   "metadata": {},
   "source": [
    "## Update the test data set with all data cleaning procedures performed so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2ce52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also reindex the dummied test set variables to make sure all the feature columns in the train set are also available in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c459f",
   "metadata": {},
   "source": [
    "## WoE Binning/Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d91849df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will analyze both categorical and numerical features based on their categorical/binned WoEs and IVs and then combine some of these binned categories together through a custom python class with fit_transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9098de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copies of the 4 training sets(by the names X_train_prepr, y_train_prepr, etc) to be preprocessed using WoE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ef2ee",
   "metadata": {},
   "source": [
    "## analyze WoEs and IVs of discrete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd203042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that takes 3 arguments: a dataframe (X_train_prepr), a string (column name), and a dataframe (y_train_prepr)\n",
    "# the function should returns a dataframe as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "136285cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the default style of the graphs to the seaborn style. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cc8ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for plotting WoE across categories that takes 2 arguments: a dataframe and a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff26c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply these on all four categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09c44927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe graphs of WOE. If there is a continuous increase in WoE across the different categories then we do not need to combine any features together and should leave all these categories as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8b8839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are no missing values in the grade column leave it as it is, otherwise createa a separate and independent category for all Missing values that would never be combined with any other category\n",
    "# you will come across this scenario when working through features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c524dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate WoE of continuous variables\n",
    "# this is same as the function we defined earlier for discrete variables\n",
    "# the only difference are the 2 lines of code that need to be commented in the function that results in the df being sorted by continuous variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c176da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this on continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82436e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine classing using the cut method if there are a large number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e66c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use the features which have\n",
    "    # very low IV\n",
    "    # which have unusually high IV\n",
    "    # WoE ranges between a very small range, implying low power of differentiating between good and bad loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9c14866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is a feature for which most of the values are inside a particular range and very few outside then \n",
    "    # create one category for values outside that range\n",
    "    # apply your approach to all other values(which are inside the range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7052db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some of the columns values would feel out of place like utilization being greater than 1 in some values which is very rare so filter those out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b055d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while plotting WOE if you have some doubt in curve you can also zoom on some portion to understand the nature of graph in that area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9aac8722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the IV is borderline close to the minimum or maximum ideal threshold, you can proceed without ignoring that feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865d6b8",
   "metadata": {},
   "source": [
    "## Define Custom Class for WoE Binning/Reengineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ecec1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will create a custom scikit-learn class to take care of all binning transformations on any given data set\n",
    "# this custom class will help us in performing k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfeb5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the reference categories, i.e. one category from each of the global features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9d62257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this custom class will create new categorical dummy features based on the cut-off points that we manually identified based on the WoE plots and IV above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "260e7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure this class so that it also allows a fit_transform method to be implemented on it, thereby allowing you to use it as part of a scikit-learn Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594f479",
   "metadata": {},
   "source": [
    "## PD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c007251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconfirm shape of the 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "400573de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46bbec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross-validation criteria\n",
    "# RepeatedStratifiedKFold automatially takes care of the class imbalance while splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e76c496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81862473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean AUROC score and Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab3c480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the pipeline on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9426b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transformed training set through our WoE_Binning custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0a4d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the column names in X_train as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96f2bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary table of our logistic regression model(name it summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b02d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in the dataframe, called 'Coefficients', with row values the transposed coefficients from the 'LogisticRegression' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbefe8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the index of every row of the dataframe with 1 to store our model intercept in 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35d11b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign our model intercept to this new row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bdc664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe by index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39044f",
   "metadata": {},
   "source": [
    "## Prediction Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fb857da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preditions on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d751fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted probabilities(name it y_hat_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "457c48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the probabilities of only the positive class (class 1 - default) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1221e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create a new DF with actual classes and the predicted probabilities\n",
    "# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "120e4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape to make sure the number of rows is same as that in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eff09b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a340a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the index of one dataframe equal to the index of another dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3f5c7",
   "metadata": {},
   "source": [
    "## Confusion Matrix and AUROC on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bcedd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a threshold value to differentiate good with bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42884466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate a new column for the predicted class based on predicted probabilities and threshold\n",
    "# we will determine this optimal threshold later in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1b467c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32ae63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values required to plot a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32a48f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32926203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b029d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e421c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Gini from AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a67d6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a PR curve\n",
    "# calculate the no skill line as the proportion of the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4408762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the no skill precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9419ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inputs for the PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5a5bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inputs for the PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d78d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a78dd2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PR AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5c621",
   "metadata": {},
   "source": [
    "## Applying the Model - Scorecard Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37913e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e56fea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with one column\n",
    "# its values are the values from the 'reference_categories' list\n",
    "# name it 'Feature name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a26ea5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a second column called 'Coefficients' which contains only 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8da85214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenates two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b6bceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we reset the index of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8674e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called 'Original feature name' which contains the value of the 'Feature name' column up to the column symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c9e748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the min and max threshholds for our scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86b900c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the minimum coefficients of each category within the original feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a346dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of the maximum coefficients of each category within the original feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac8691f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new columns that has the imputed calculated Score based on the multiplication of the coefficient by the ratio of the differences between\n",
    "# maximum & minimum score and maximum & minimum sum of cefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1bf24313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the calculated score of the Intercept (i.e. the default score for each loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dc2657e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the values of the 'Score - Calculation' column and store them in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "543f897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the min and max possible scores of our scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88818024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both our min and max scores are out by +1\n",
    "# we need to manually adjust this\n",
    "# to decide which one we'll evaluate based on the rounding differences of the minimum category within each Original Feature Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e188b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get by deducting 1 from the Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "feb1f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck min and max possible scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd043803",
   "metadata": {},
   "source": [
    "## Calculating credit scores for all observations in the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ff8f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transformed test set through our WoE_Binning custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95d3ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert an Intercept column in its beginning to align with the # of rows in scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6229a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of our final scorecard scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bf4b59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shapes of test set and scorecard before doing matrix dot multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ee9b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the test set has a few less columns than the rows in scorecard due to the reference categories\n",
    "# since the reference categories will always be scored as 0 based on the scorecard, it is safe to add these categories to the end of test set with 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9cb4b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to reshape scorecard_scores so that it is of proper shape to allow for matrix dot multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60a94f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix dot multiplication of test set with scorecard scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c99b3",
   "metadata": {},
   "source": [
    "## Setting loan approval cut-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "869dcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Youden's J-Statistic to identify the best threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cc9bdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the index of the largest J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0401c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "13cbdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this means that based on the Youden's J statistic, this is the ideal probability threshold which minimizes the FPR and maximimizes the TPR\n",
    "# which means all samples with a predicted probability higher than this should be classified as in Default and vice versa\n",
    "# this ideal threshold might appear to be counterintuitive compared to the default probability threshold of 0.5 but remember that we used the class_weight parameter when fitting our logistic regression model that would have helped us\n",
    "\n",
    "# we can confirm this by looking at our original confusion matrix with the updated threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8577ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fae9f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate a new column for the predicted class based on predicted probabilities and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e9cf41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ddfcf9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the updated confusion matrix would show a marked improvement in the TPR at marginal cost of lower TNR but at the same time, FNR has improved drastically with a corresponding marginal increase in FPR\n",
    "\n",
    "# find the corresponding acceptance and rejection rates on the test set at this ideal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b0794619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DF comprising of the thresholds from the ROC output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b8b07a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Score corresponding to each threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a838b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function called 'n_approved' which assigns a value of 1 if a predicted probability is greater than the parameter p which is a threshold and a value of 0 if it is not\n",
    "# then it sums the column.\n",
    "# for given any percentage values the function will return the number of rows wih estimated probabilites greater than the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "00b90a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming that all credit applications above a given probability of being 'good' will be approved\n",
    "# when we apply the 'n_approved' function to a threshold it will return the number of approved applications\n",
    "# here we calculate the number of approved appliations for all thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb181639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we calculate the number of rejected applications for each threshold\n",
    "# it is the difference between the total number of applications and the approved applications for that threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1630dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approval rate equals the ratio of the approved applications and all applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b5873b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejection rate equals one minus approval rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d7a0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the approval and rejection rates at our ideal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b63291ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the above rates with the case of the default 0.5 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b26cc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you would find that 0.5 threshold would result in a very high rejection rate with a corresponding loss of business\n",
    "\n",
    "# we will stick with our ideal threshold and the corresponding Creidt Score of (fill yourself) and can also monitor the model's performance in production if more data were available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92abd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
